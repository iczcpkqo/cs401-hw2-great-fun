== SOURCE
https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist
== AGENT
Microsoft 
== GOAL
experiment in conversational understanding creating a twitter chat bot
== DATA
the data was being collected through user input and conversations
== METHODS
not specified but user maintained 
== RESULTS
results caused the chat bot to say crazy and inapropriate things on its twitter
== ISSUES
the issues where evident in its antisemetic and racist 
== SCORE
8
== COMMENTS
a perfect example of the dangers of the internet when unchecked and from a simple chat bot how quickly it can be changed into something bad 